# 构建 AI 原生工程团队

编程智能体如何加速软件开发生命周期

## 引言

AI 模型正在迅速扩展其能执行的任务范围，这对工程领域具有重大意义。前沿系统现在可以维持数小时的推理：截至 2025 年 8 月，METR 发现领先的模型可以完成 2 小时 17 分钟 的连续工作，并以大约 50% 的置信度 产生正确答案。

这种能力正在迅速提升，任务长度大约每七个月翻一番。仅在几年前，模型只能处理大约 30 秒的推理——仅够用于简单的代码建议。如今，随着模型能够维持更长的推理链，整个软件开发生命周期（SDLC）都有可能获得 AI 的协助，使编程智能体（Coding Agents）能够有效地参与规划、设计、开发、测试、代码审查和部署。

[图表说明：展示了不同 LLM 在 50% 的时间内能完成的软件工程任务的时间跨度。从 2020 年 GPT-2/3 的简单事实查找，到 2025 年 Claude 3.7 Sonnet、o3、Grok 4、GPT-5 等模型能够处理如“修复 Python 库中的 bug”、“利用缓冲区溢出”等耗时数小时的任务。]

在本指南中，我们将分享真实的案例，概述 AI 智能体如何为软件开发生命周期做出贡献，并为工程领导者提供切实可行的指导，帮助他们从今天开始构建 AI 原生的团队和流程。

## AI 编程：从自动补全到智能体

AI 编程工具已经远远超出了其作为自动补全助手的起源。早期的工具处理快速任务，如建议下一行代码或填充函数模板。随着模型获得更强的推理能力，开发人员开始通过 IDE 中的聊天界面与智能体互动，进行结对编程和代码探索。

今天的编程智能体可以生成整个文件，搭建新项目，并将设计转化为代码。它们可以推理多步骤问题，如调试或重构，智能体的执行环境也正从单个开发者的机器转移到基于云的多智能体环境。这正在改变开发人员的工作方式，使他们花在 IDE 内生成代码的时间变少，而更多的时间用于委派整个工作流。

跨系统的统一上下文

单一模型可以读取代码、配置和遥测数据，在以前需要单独工具的层级之间提供一致的推理。

结构化工具执行

模型现在可以直接调用编译器、测试运行器和扫描器，产生可验证的结果，而不仅仅是静态建议。

持久项目记忆

长上下文窗口和压缩等技术允许模型跟踪一个功能从提案到部署的全过程，记住之前的设计选择和约束。

评估循环

模型输出可以自动针对基准（单元测试、延迟目标或风格指南）进行测试，因此改进是基于可衡量的质量。

在 OpenAI，我们亲眼见证了这一点。开发周期加快了，曾经需要数周的工作现在只需几天即可交付。团队更容易跨领域移动，更快地熟悉陌生项目，并以更大的敏捷性和自主性在整个组织中运作。许多常规且耗时的任务，从为新代码编写文档、提取相关测试、维护依赖项到清理功能标志（feature flags），现在都完全委托给了 Codex。

然而，工程的某些方面保持不变。代码的真正所有权——特别是对于新的或模棱两可的问题——仍然属于工程师，某些挑战超出了当前模型的能力。但有了像 Codex 这样的编程智能体，工程师现在可以将更多时间花在复杂和新颖的挑战上，专注于设计、架构和系统级推理，而不是调试或机械式实现。

在接下来的章节中，我们将分解 SDLC 的每个阶段如何随着编程智能体而变化——并概述您的团队可以采取的具体步骤，开始作为一个 AI 原生工程组织运作。

## 规划 (Plan)

整个组织的团队通常依赖工程师来确定某个功能是否可行、构建需要多长时间以及涉及哪些系统或团队。虽然任何人都可以起草规范，但制定准确的计划通常需要对代码库有深入的了解，并与工程部门进行多轮迭代，以发现需求、澄清边缘情况并就技术上的现实性达成一致。

### 编程智能体如何提供帮助

AI 编程智能体在规划和范围界定期间为团队提供即时的、代码感知的洞察。例如，团队可以构建工作流，将编程智能体与其问题跟踪系统连接起来，读取功能规范，将其与代码库进行交叉引用，然后标记歧义、将工作分解为子组件或估算难度。

编程智能体还可以立即跟踪代码路径，显示某个功能涉及哪些服务——这在以前需要数小时或数天在大型代码库中手动挖掘。

### 工程师转而做什么

团队将更多时间花在核心功能工作上，因为智能体提供了以前需要开会进行产品对齐和范围界定所需的上下文。关键的实施细节、依赖关系和边缘情况被提前识别，从而能够以更少的会议做出更快的决策。

| 委派 (Delegate) | AI 智能体可以进行可行性和架构分析的第一轮尝试。它们阅读规范，将其映射到代码库，识别依赖关系，并提出需要澄清的歧义或边缘情况。                                   |
| --------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 审查 (Review)   | 团队审查智能体的发现，以验证准确性，评估完整性，并确保估算反映真实的技术约束。故事点（Story point）分配、工作量大小评估和识别非显而易见的风险仍然需要人类判断。 |
| 掌控 (Own)      | 战略决策——如优先级、长期方向、排序和权衡——仍然由人类主导。团队可以询问智能体选项或后续步骤，但规划和产品方向的最终责任由组织承担。                          |

入门清单

    ● 确定需要特征和源代码之间对齐的常见流程。常见领域包括功能范围界定和工单创建。

    ● 从实施基本工作流开始，例如标记和去重问题或功能请求。

    ● 考虑更高级的工作流，例如根据初始功能描述向工单添加子任务。或者当工单达到特定阶段时启动智能体运行，以补充更多详细描述。

## 设计 (Design)

设计阶段往往因基础设置工作而变慢。团队花费大量时间连接样板代码、集成设计系统以及完善 UI 组件或流程。模型图与实现之间的不一致会导致返工和长反馈周期，而且探索替代方案或适应不断变化的需求的带宽有限，会延迟设计验证。

### 编程智能体如何提供帮助

AI 编程工具通过搭建样板代码、构建项目结构以及即时实施设计令牌（Design Tokens）或风格指南，极大地加速了原型设计。工程师可以用自然语言描述所需的功能或 UI 布局，并接收符合团队规范的原型代码或组件存根。

它们可以将设计直接转换为代码，建议可访问性改进，甚至分析代码库中的用户流程或边缘情况。这使得在数小时而不是数天内迭代多个原型成为可能，并且可以尽早进行高保真原型设计，为团队提供更清晰的决策依据，并在流程的早期就启用客户测试。

### 工程师转而做什么

随着常规设置和翻译任务由智能体处理，团队可以将注意力转移到高杠杆工作上。工程师专注于完善核心逻辑，建立可扩展的架构模式，并确保组件符合质量和可靠性标准。设计师可以花更多时间评估用户流程和探索替代概念。协作努力从实施开销转移到了改进底层产品体验上。

| 委派 (Delegate) | 智能体处理初始实施工作，包括搭建项目、生成样板代码、将模型图转换为组件以及应用设计令牌或风格指南。 |
| --------------- | -------------------------------------------------------------------------------------------------- |
| 审查 (Review)   | 团队审查智能体的输出，确保组件遵循设计规范，符合质量和可访问性标准，并能与现有系统正确集成。       |
| 掌控 (Own)      | 团队拥有总体设计系统、UX 模式、架构决策以及用户体验的最终方向。                                    |

入门清单

    ● 使用接受文本和图像输入的多模态编程智能体。

    ● 通过 MCP（模型上下文协议）将设计工具与编程智能体集成。

    ● 通过 MCP 以编程方式公开组件库，并将其与您的编码模型集成。

    ● 构建工作流，映射：设计 → 组件 → 组件的实现。

    ● 利用类型化语言（例如 Typescript）为智能体定义有效的属性（props）和子组件。

## 构建 (Build)

构建阶段是团队感到摩擦最多的地方，也是编程智能体具有最明显影响的地方。工程师花费大量时间将规范转换为代码结构，将服务连接在一起，在代码库中复制模式，以及填充样板代码，即使是很小的功能也需要数小时的忙碌工作。

随着系统的增长，这种摩擦会加剧。大型单体代码库（Monorepos）积累了模式、惯例和历史遗留问题，减慢了贡献者的速度。工程师花在重新发现做某事的“正确方法”上的时间可能与实现功能本身一样多。在规范、代码搜索、构建错误、测试失败和依赖管理之间不断的上下文切换增加了认知负荷——长期运行任务期间的中断会打破心流并进一步延迟交付。

### 编程智能体如何提供帮助

在 IDE 和 CLI 中运行的编程智能体通过处理更大的、多步骤的实施任务来加速构建阶段。它们不再只是生成下一个函数或文件，而是在一次协调运行中端到端地生成完整的功能——数据模型、API、UI 组件、测试和文档。凭借对整个代码库的持续推理，它们处理曾经需要工程师手动跟踪代码路径的决策。

对于长期运行的任务，智能体可以：

    ● 根据书面规范起草整个功能实现。

    ● 在几十个文件中搜索和修改代码，同时保持一致性。

    ● 生成符合惯例的样板代码：错误处理、遥测、安全包装器或风格模式。

    ● 在构建错误出现时修复它们，而不是暂停等待人工干预。

    ● 作为单一工作流的一部分，在实施的同时编写测试。

    ● 生成符合内部指南并包含 PR 消息的、可直接用于 diff 的变更集。

实际上，这将大部分机械的“构建工作”从工程师转移到了智能体。智能体成为第一轮实施者；工程师成为审阅者、编辑和方向的来源。

### 工程师转而做什么

当智能体能够可靠地执行多步骤构建任务时，工程师将注意力转移到更高阶的工作：

    ● 在实施之前澄清产品行为、边缘情况和规范。

    ● 审查 AI 生成代码的架构含义，而不是进行机械的连线。

    ● 完善需要深厚领域推理的业务逻辑和性能关键路径。

    ● 设计指导智能体生成代码的模式、护栏和惯例。

    ● 与产品经理和设计合作迭代功能意图，而不是样板代码。

工程师不再将功能规范“翻译”成代码，而是专注于正确性、连贯性、可维护性和长期质量，这些仍然是人类环境最重要的地方。

| 委派 (Delegate) | 智能体起草明确指定功能的第一次实施通过——脚手架、CRUD 逻辑、连线、重构和测试。随着长时间推理能力的提高，这越来越多地涵盖完整的端到端构建，而不是孤立的片段。 |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 审查 (Review)   | 工程师评估设计选择、性能、安全性、迁移风险和领域对齐，同时纠正智能体可能遗漏的细微问题。他们塑造和完善 AI 生成的代码，而不是进行机械工作。                    |
| 掌控 (Own)      | 工程师保留对需要深刻系统直觉的工作的所有权：新的抽象、跨切面架构变更、模糊的产品需求和长期可维护性权衡。                                                      |

案例： Cloudwalk 的工程师、产品经理、设计师和运营人员每天都使用 Codex 将规范转化为工作代码，无论他们需要脚本、新的欺诈规则还是几分钟内交付的完整微服务。它消除了构建阶段的繁琐工作，赋予每位员工以惊人速度实现想法的能力。

入门清单

    ● 从明确指定的任务开始。

    ● 让智能体通过 MCP 使用规划工具，或通过编写提交到代码库的 PLAN.md 文件。

    ● 检查智能体尝试执行的命令是否成功。

    ● 迭代 AGENTS.md 文件，以解锁像运行测试和 linter 这样的智能体循环来接收反馈。

## 测试 (Test)

开发人员经常难以确足够的测试覆盖率，因为编写和维护全面的测试需要时间、上下文切换以及对边缘情况的深刻理解。团队经常面临在快速行动和编写详尽测试之间的权衡。当截止日期临近时，测试覆盖率往往是第一个受害者。

即使编写了测试，随着代码的演变保持其更新也会引入持续的摩擦。测试可能会变得脆弱（brittle），因不明原因失败，并且随着底层产品的变化可能需要自己的重大重构。高质量的测试让团队能以更大的信心更快地发布。

### 编程智能体如何提供帮助

AI 编程工具可以通过几种强大的方式帮助开发人员编写更好的测试。首先，它们可以根据阅读需求文档和功能代码的逻辑来建议测试用例。模型在建议边缘情况和故障模式方面可能出奇地好，这对于开发人员来说可能很容易忽略，特别是当他们专注于功能并需要第二意见时。

此外，模型可以帮助测试随着代码的演变保持最新，减少重构的摩擦，避免陈旧的测试变得不稳定。通过处理测试编写的基本实现细节和浮现边缘情况，编程智能体加速了开发测试的过程。

### 工程师转而做什么

使用 AI 工具编写测试并不能消除开发人员思考测试的需要。事实上，随着智能体消除了生成代码的障碍，测试作为应用程序功能真理来源的功能变得越来越重要。由于智能体可以运行测试套件并根据输出进行迭代，因此定义高质量测试往往是允许智能体构建功能的第一步。

相反，开发人员更多地专注于看到测试覆盖率的高级模式，建立并挑战模型对测试用例的识别。加快测试编写速度使开发人员能够更快地发布功能，并承担更雄心勃勃的功能。

| 委派 (Delegate) | 工程师将基于功能规范生成测试用例的初始过程委派给智能体。他们还会使用模型进行第一轮测试生成。让模型在与功能实现分开的会话中生成测试通常很有帮助。                                                        |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 审查 (Review)   | 工程师必须彻底审查模型生成的测试，以确保模型没有走捷径或实施桩测试（stubbed tests）。工程师还要确保测试可由其智能体运行；智能体具有运行的适当权限，并且智能体具有它可以运行的不同测试套件的上下文意识。 |
| 掌控 (Own)      | 工程师负责使测试覆盖率与功能规范和用户体验期望保持一致。对抗性思维、映射边缘情况的创造力以及关注测试意图仍然是关键技能。                                                                                |

入门清单

    ● 引导模型作为一个单独的步骤实施测试，并验证新测试在移动到功能实现之前是否失败。

    ● 在您的 AGENTS.md 文件中设置测试覆盖率指南。

    ● 给智能体具体的代码覆盖率工具示例，它可以调用这些工具来了解测试覆盖率。

## 审查 (Review)

平均而言，开发人员每周花费 2-5 小时进行代码审查。团队经常面临选择：是投入大量时间进行深度审查，还是对看似微小的更改进行快速的“足够好”的通过。当这种优先级排序错误时，错误就会溜进生产环境，给用户带来问题并造成大量返工。

### 编程智能体如何提供帮助

编程智能体允许代码审查过程扩展，以便每个 PR（拉取请求）都能获得一致的基准关注。与传统的静态分析工具（依赖于模式匹配和基于规则的检查）不同，AI 审查者实际上可以执行部分代码，解释运行时行为，并跟踪跨文件和服务的逻辑。然而，要有效，模型必须经过专门训练以识别 P0 和 P1 级别的错误，并调整为提供简洁、高信号的反馈；过于冗长的响应会像嘈杂的 lint 警告一样被忽略。

### 工程师转而做什么

在 OpenAI，我们发现 AI 代码审查让工程师更有信心，确信他们不会将重大错误发布到生产环境中。通常，代码审查会在拉入另一位工程师之前捕获贡献者可以纠正的问题。代码审查并不一定能使拉取请求过程更快，特别是如果它发现了有意义的错误——但它确实可以防止缺陷和中断。

#### 委派 vs. 审查 vs. 掌控

即使有 AI 代码审查，工程师仍然负责确保代码准备好发布。实际上，这意味着阅读并理解变更的含义。工程师将初始代码审查委托给智能体，但拥有最终审查和合并过程。

| 委派 (Delegate) | 工程师将初始代码审查委派给智能体。在拉取请求被标记为准备好让队友审查之前，这可能会发生多次。                 |
| --------------- | ------------------------------------------------------------------------------------------------------------ |
| 审查 (Review)   | 工程师仍然审查拉取请求，但更多地强调架构对齐；是否实施了可组合模式，是否使用了正确的惯例，功能是否符合要求。 |
| 掌控 (Own)      | 工程师最终拥有部署到生产环境的代码；他们必须确保其运行可靠并满足预期要求。                                   |

案例： Sansan 使用 Codex 审查竞争条件（race conditions）和数据库关系，这是人类经常忽略的问题。Codex 还能捕捉不恰当的硬编码，甚至预测未来的可扩展性问题。

入门清单

    ● 整理工程师进行的黄金标准 PR 示例，包括代码更改和留下的评论。将其保存为评估集以衡量不同的工具。

    ● 选择一个具有专门针对代码审查训练的模型的产。我们发现通用模型经常吹毛求疵，信噪比低。

    ● 定义您的团队将如何衡量审查是否高质量。我们建议跟踪 PR 评论的反应（Reactions），以此作为标记好坏审查的低摩擦方式。

    ● 从小处着手，一旦您对审查结果获得信心，就迅速推广。

## 文档 (Document)

大多数工程团队都知道他们的文档落后了，但发现追赶成本高昂。关键知识通常由个人掌握，而不是捕获在可搜索的知识库中，现有的文档很快就会过时，因为更新它们会将工程师从产品工作中拉走。即使团队进行文档冲刺，结果通常也是一次性的努力，一旦系统演变就会腐烂。

### 编程智能体如何提供帮助

编程智能体非常有能力基于阅读代码库来总结功能。它们不仅可以写出代码库的部分如何工作，还可以生成像 Mermaid 这样语法的系统图。随着开发人员使用智能体构建功能，他们还可以通过简单地提示模型来更新文档。使用 AGENTS.md，可以自动在每个提示中包含根据需要更新文档的指令，以保持一致性。

由于可以通过 SDK 以编程方式运行编程智能体，它们也可以合并到发布工作流中。例如，我们可以要求编程智能体审查发布中包含的提交并总结关键更改。结果是文档成为交付管道的内置部分：生成更快，更容易保持最新，不再依赖某人“找时间”。

### 工程师转而做什么

工程师从手工编写每一份文档转变为塑造和监督系统。他们决定文档如何组织，添加决策背后的重要“原因”，为智能体设置明确的标准和模板以供遵循，并审查关键或面向客户的部分。他们的工作变成确保文档结构化、准确，并连接到交付过程中，而不是自己进行所有的打字工作。

| 委派 (Delegate) | 将低风险、重复性的工作完全移交给 Codex，如文件和模块的初稿摘要、输入输出的基本描述、依赖列表和拉取请求更改的简短摘要。      |
| --------------- | --------------------------------------------------------------------------------------------------------------------------- |
| 审查 (Review)   | 工程师审查和编辑由 Codex 起草的重要文档，如核心服务概述、公共 API 和 SDK 文档、操作手册（runbooks）和架构页面，然后才发布。 |
| 掌控 (Own)      | 工程师仍然负责整体文档策略和结构、智能体遵循的标准和模板，以及所有涉及法律、监管或品牌风险的面向外部或安全关键的文档。      |

入门清单

    ● 通过提示编程智能体来试验文档生成。

    ● 将文档指南纳入您的 AGENTS.md。

    ● 识别可以自动生成文档的工作流（例如发布周期）。

    ● 审查生成内容的质量、正确性和重点。

## 部署与维护 (Deploy & Maintain)

理解应用程序日志对于软件可靠性至关重要。在事故期间，软件工程师会参考日志工具、代码部署和基础设施更改来确定根本原因。这个过程通常令人惊讶地依赖人工，并且需要开发人员在不同的系统之间来回切换，在像事故这样的高压情况下消耗关键的分钟数。

### 编程智能体如何提供帮助

使用 AI 编程工具，除了代码库的上下文之外，您还可以通过 MCP 服务器提供对日志工具的访问。这允许开发人员拥有一个单一的工作流，他们可以提示模型查看特定端点的错误，然后模型可以使用该上下文遍历代码库并找到相关的 bug 或性能问题。由于编程智能体还可以使用命令行工具，它们可以查看 git 历史记录以识别可能导致日志跟踪中捕获的问题的具体更改。

### 工程师转而做什么

通过自动化日志分析和事故分诊（triage）的繁琐方面，AI 使工程师能够专注于更高级别的故障排除和系统改进。工程师不再手动关联日志、提交和基础设施更改，而是专注于验证 AI 生成的根本原因，设计弹性的修复方案，并制定预防措施。这种转变减少了花在被动“救火”上的时间，使团队能够在主动可靠性工程和架构改进上投入更多精力。

| 委派 (Delegate) | 许多运维任务可以委派给智能体——解析日志、浮现异常指标、识别可疑代码更改，甚至提出热修复建议。                   |
| --------------- | ---------------------------------------------------------------------------------------------------------------- |
| 审查 (Review)   | 工程师审查和完善 AI 生成的诊断，确认准确性，并批准补救步骤。他们确保修复符合可靠性、安全性和合规性标准。         |
| 掌控 (Own)      | 关键决策权留在工程师手中，特别是对于新奇的事故、敏感的生产变更或模型置信度低的情况。人类仍然负责判断和最终签署。 |

案例： Virgin Atlantic 使用 Codex 来加强团队部署和维护系统的方式。Codex VS Code 扩展为工程师提供了一个单一的地方来调查日志，跨代码和数据跟踪问题，并通过 Azure DevOps MCP 和 Databricks Managed MCP 审查更改。通过在 IDE 内统一这种操作上下文，Codex 加快了根本原因的发现，减少了手动分诊，并帮助团队专注于验证修复和提高系统可靠性。

入门清单

    ● 将 AI 工具连接到日志和部署系统：将 Codex CLI 或类似工具与您的 MCP 服务器和日志聚合器集成。

    ● 定义访问范围和权限：确保智能体可以访问相关日志、代码存储库和部署历史记录，同时保持安全最佳实践。

    ● 配置提示模板：为常见的操作查询创建可重用的提示，例如“调查端点 X 的错误”或“分析部署后的日志峰值”。

    ● 测试工作流：运行模拟事故场景，以确保 AI 浮现正确的上下文，准确跟踪代码，并提出可操作的诊断。

    ● 迭代和改进：从真实事故中收集反馈，调整提示策略，并随着系统和流程的发展扩展智能体能力。

## 结论

编程智能体正在通过承担传统上拖慢工程团队速度的机械性、多步骤工作来改变软件开发生命周期。凭借持续的推理、统一的代码库上下文以及执行真实工具的能力，这些智能体现在处理从范围界定和原型设计到实施、测试、审查甚至操作分诊的任务。工程师仍然牢牢控制着架构、产品意图和质量——但编程智能体越来越多地作为第一轮实施者和 SDLC 每个阶段的持续协作者。

这种转变不需要彻底的推倒重来；随着编程智能体变得更加能干和可靠，小的、有针对性的工作流会迅速复合。从范围明确的任务开始，投资于护栏，并迭代扩展智能体责任的团队，在速度、一致性和开发人员专注度方面看到了有意义的收益。

如果您正在探索编程智能体如何加速您的组织，或者正在准备您的第一次部署，请联系 OpenAI。我们将帮助您将编程智能体转化为真正的杠杆——设计跨越规划、设计、构建、测试、审查和运营的端到端工作流，并帮助您的团队采用使 AI 原生工程成为现实的生产就绪模式。
